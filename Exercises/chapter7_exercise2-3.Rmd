---
title: "ch7_exercises"
author: "Anna"
date: "2025-01-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1) See my example in pdf format.

2) In Chapter 6, you were asked to create word embeddings. Improve that code based on the new information on word embeddings you learned in this chapter.

For this task we need to load the data and preprocessing from chapter 6, you can open the two files in parallel and load in what you need. We start with the cleaned data here:

```{r}
head(clean_doc, n =2)
```

Now we need to make decisions based on the data and our task. Waiting long for our test model to load doesn't sound fun so we use the faster "cbow" algorithm. We don't want to overfit and reduce time efforts but we do have a quite large corpus here, so we go with 50 dimensions initially. The bigger the context window, the more calculations are required. We use a context window of 5 words for cbow, because or text does have some complexity to it. GO ON
Of cause we choose the encoding "UTF-8".

```{r}
word2vec(
  clean_doc,
  type = "cbow",
  dim = 50,
  window = 5L,
  iter = 5L,
  lr = 0.05,
  hs = FALSE,
  negative = 5L,
  sample = 0.001,
  min_count = 5L,
  split = c(" \n,.-!?:;/\"#$%&'()*+<=>@[]\\^_`{|}~\t\v\f\r", ".\n?!"),
  stopwords = character(),
  threads = 1L,
  encoding = "UTF-8"
)
```

Now we have a first model, in a next step we would evaluate this by looking at models with different hyperparameter values. We want to do this initial check based on our task, data and literature knowledge so we don't run an unnecessary amount of models. You will do the evaluation step in exercise 3.

3) In Chapter 6, you were asked to replicate the LDA model based on party manifestos. Use the code from this chapter to tune hyperparameters and evaluate your model. 

We start with the model from chapter 6:

```{r}
dtm_aus
```
We already evaluated k, so we keep 15 topics here. We now whant to choose further hyperparameters.

```{r eval=FALSE, include=T}
?topicmodels::LDA
LDA(x, k, method = "VEM", control = NULL, model = NULL, ...) 
```

We go deeper than above and evaluate some hyperparameter options:

Choose burnin and iter value based on log-likelihood:

Based on perplexity:

Evaluation with the oolong package:
